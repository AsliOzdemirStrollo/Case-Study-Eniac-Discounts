# -*- coding: utf-8 -*-
"""Copy of Project_Notebook_cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jFPdC2Js0C9FosKHgsAJoxVUcpcK_iph
"""

import pandas as pd

def import_csv(url):
  path = "https://drive.google.com/uc?export=download&id="+url.split("/")[-2]
  return pd.read_csv(path)

orderlines_url = "https://drive.google.com/file/d/1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG/view?usp=sharing"
orders_url = "https://drive.google.com/file/d/1Vu0q91qZw6lqhIqbjoXYvYAQTmVHh6uZ/view?usp=sharing"
products_url = "https://drive.google.com/file/d/1afxwDXfl-7cQ_qLwyDitfcCx3u7WMvkU/view?usp=sharing"
brands_url = "https://drive.google.com/file/d/1XGyabaa4mAkjixMk3XPgx_14OoSse3rs/view?usp=sharing"

orderlines = import_csv(orderlines_url)
orders = import_csv(orders_url)
products = import_csv(products_url)
brands = import_csv(brands_url)

orderlines_df = orderlines.copy()

orders_df = orders.copy()

products_df = products.copy()

brands_df = brands.copy()

"""# 1.&nbsp; **Duplicates**
We can check for duplicates using the pandas [.duplicated()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) method.

We can then delete these rows, if we wish, using [.drop_duplicates()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)
"""

# orders
orders_df.duplicated().sum()

# orderlines
orderlines_df.duplicated().sum()

# products
products_df.duplicated().sum()

# brands
brands_df.duplicated().sum()

"""## Result: products have duplicates



"""

products_df = products_df.drop_duplicates()

# products check again
products_df.duplicated().sum()

"""# 2.&nbsp; **`.info()`**

## ORDERS:
"""

orders_df.info()

"""### **1.created_date is not datetime, 2.total_paid column had missing rows**"""

orders_df['created_date'] = pd.to_datetime(orders_df['created_date'])
orders_df.info()

# how much % of the date frame has missing rows
print(f"5 missing values represents {((orders_df.total_paid.isna().sum() / orders_df.shape[0])*100).round(5)}% of the rows in our DataFrame")

"""### As there is such a tiny amount of missing values, we will simply delete these rows, as we have enough data without them."""

orders_df = orders_df.loc[~orders.total_paid.isna(), :] #remove the rows with no values

orders_df.info() #check again

orders_cl = orders_df.copy()

"""## ORDERLINES:"""

orderlines_df.info()

"""### **unit_price & date formats are object. 1. unit_price must be float, 2. date must have datetime format.**"""

orderlines_df['date'] = pd.to_datetime(orderlines_df['date'])

"""### ** Alternative: Solution with keeping the rows with 2 dots (not losing data)**"""

# Function to detect multiple dots
import re

def has_multiple_dots(text):
    return bool(re.search(r'.*\..*\..*', str(text)))

# Function to FIX entries with multiple dots
def fix_multiple_dots(value):
    if has_multiple_dots(value):
        parts = str(value).split('.')
        return parts[0] + '.' + ''.join(parts[1:])  # Keep only the first dot
    return value

# Apply the fix
orderlines_df['unit_price'] = orderlines_df['unit_price'].apply(fix_multiple_dots)


# Convert to numeric and fill NaNs with 0
orderlines_df['unit_price'] = pd.to_numeric(orderlines_df['unit_price'], errors='coerce').fillna(0)

orderlines_df.info() #check again

orderlines_df.shape[0]

"""### **REAL SOLUTION: Solution with removing the rows with 2 dots (losing data)**"""

orderlines_df.unit_price.str.contains("\d+\.\d+\.\d+").value_counts()

two_dot_percentage = ((orderlines_df.unit_price.str.contains("\d+\.\d+\.\d+").value_counts()[1] / orderlines_df.shape[0])*100).round(2)

print(f"The 2 dot problem represents {two_dot_percentage}% of the rows in our DataFrame")

# remove them
two_dot_order_ids_list = orderlines_df.loc[orderlines_df.unit_price.str.contains("\d+\.\d+\.\d+"), "id_order"]

orderlines_df = orderlines_df.loc[~orderlines_df.id_order.isin(two_dot_order_ids_list)]

orderlines_df.shape[0] # this much rows left

# now convert to numeric
orderlines_df["unit_price"] = pd.to_numeric(orderlines_df["unit_price"])

orderlines_df.info() #check again

orderlines_cl = orderlines_df.copy()

"""## PRODUCTS:"""

products_df.info()

"""### **1. price & promo_price are objects. They must be numeric. 2. desc, price and type have missing rows.**"""

# missing values
products_df["desc"].isna().sum()

# 7 is a very small number to have missing, let's have a closer look
products_df.loc[products_df['desc'].isna(), :]

"""### **We have 2 choices here:**

We can quickly and easily remove these rows.
Or, alternatively, the products names here are quite descriptive, so I'm tempted to just copy them to the description column, so that there is a description if we later want utilise this column. I wouldn't recommend this if this DataFrame was the source of truth for our website. But this is not the case here, and we're not faking any information (guessing a price or so), so I'm happy with this option
"""

products_df.loc[products_df['desc'].isna(), 'desc'] = products_df.loc[products_df['desc'].isna(), 'name']

products_df.loc[products_df['desc'].isna(), :]

products_df["desc"].isna().sum()

"""Did you also notice above that we have the dreaded two decimal point problem in both the price and promo_price columns? We can also see prices with 3 decimal places, prices should have 2 decimal places: this gives us more cause for concern"""

products_df.price.isna().sum()

missing_percent = products_df.price.isna().value_counts(normalize=True).loc[True] * 100
print(f"The missing values in price are {missing_percent.round(2)}% of all rows in the DataFrame")

"""### Let's simply delete these rows to ensure that we can trust the numbers in our final DataFrame. Afterall, the price is very important when investigating discounts."""

products_df = products_df.loc[~products['price'].isna()]

"""Price: First, let's see how many values are affected by the 2-decimal-dot problems or 3 decimal places."""

price_problems_number = products_df.loc[(products_df.price.astype(str).str.contains("\d+\.\d+\.\d+"))|(products_df.price.astype(str).str.contains("\d+\.\d{3,}")), :].shape[0]
price_problems_number

print(f"The column price has in total {price_problems_number} wrong values. This is {round(((price_problems_number / products_df.shape[0]) * 100), 2)}% of the rows of the DataFrame")

"""### 5.15% is a reasonable amount of our data. However, the price column will be important to understanding discounts, so I'd like it to be very trustworthy as we are basing business decisions on it. Therefore, we'll delete these rows"""

products_df = products_df.loc[(~products_df.price.astype(str).str.contains("\d+\.\d+\.\d+"))&(~products_df.price.astype(str).str.contains("\d+\.\d{3,}")), :]

products_df["price"] = pd.to_numeric(products_df["price"])

"""### promo_price: Again, let's begin by seeing how many values are affected by the 2-decimal-dots problem, or the 3 decimal-places problem"""

promo_problems_number = products_df.loc[(products_df.promo_price.astype(str).str.contains("\d+\.\d+\.\d+"))|(products_df.promo_price.astype(str).str.contains("\d+\.\d{3,}")), :].shape[0]
promo_problems_number

print(f"The column promo_price has in total {promo_problems_number} wrong values. This is {round(((promo_problems_number / products_df.shape[0]) * 100), 2)}% of the rows of the DataFrame")

"""### better to delete the column then"""

products_cl = products_df.drop(columns=["promo_price"])

products_cl.info()  #check again

brands_df.info()

brands_cl = brands_df.copy()

"""# 3.&nbsp; Don't forget to download/save your new DataFrames. Also, give them an obvious name, so that you know they are the cleaned version and not the original DataFrame."""

#from google.colab import files

#orders_df.to_csv("orders_cl.csv", index=False)
#files.download("orders_cl.csv")

#orderlines_df.to_csv("orderlines_cl.csv", index=False)
#files.download("orderlines_cl.csv")

#products_cl.to_csv("products_cl.csv", index=False)
#files.download("products_cl.csv")